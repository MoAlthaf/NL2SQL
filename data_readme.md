# Data and Results Documentation

---

##  data/raw/

### File(s): train_spider.json, dev.json, train_others.json, dev_others.json  
- **Type**: Input  
- **Source**: [Spider Dataset on Yale NLP](https://yale-lily.github.io/spider)  
- **Used by**: `data/scripts/prepare_dataset.py`  
- **Description**: Original Spider dataset files in JSON format. Each file contains natural language questions, SQL queries, and associated database schema information.

---

##  data/processed/

### File: train.csv  
- **Type**: Intermediate Input  
- **Generated by**: `data/scripts/prepare_dataset.py`  
- **Used by**: `nl2nl.py`  
- **Description**: Cleaned version of `train_spider.json` and `train_others.json`. Contains question and schema in tabular format.

### File: dev.csv  
- **Type**: Intermediate Input  
- **Generated by**: `data/scripts/prepare_dataset.py`  
- **Used by**: `nl2nl.py`  
- **Description**: Cleaned version of `dev.json` and `dev_others.json`. Same format as train.csv, used for validation.

### File: output_paraphrased.csv  
- **Type**: Intermediate Output  
- **Generated by**: `nl2nl.py`  
- **Used by**: `nl2sql.py`  
- **Description**: Contains paraphrased versions of natural language questions from the original dataset. Columns:
  - `original_question`
  - `paraphrased_question`
  - `schema`
  - `question_id`

---

##  results/

### File: results.csv  
- **Type**: Final Output  
- **Generated by**: `nl2sql.py`  
- **Used by**: notebook analyzer and downstream evaluation scripts  
- **Description**: Final result file containing all stages of processing and evaluation. Columns:
  - `original_question`
  - `paraphrased_question`
  - `ground_truth_sql`
  - `generated_sql`
  - `db_id`
  - `matched`
  - `attempts`

